---
title: "FinPred"
author: "Jose Rodriguez-Acosta"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{FinPred}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
)
```

## Introduction
In the field of finance, developing an
understanding of assets’ returns over time is important for forming decisions related to trading
such assets. Here, an asset’s return represents the relative change in price of the asset over a
specified time period. Returns are often modeled rather than the prices themselves in practice
due to them having properties that are more desirable for this task (Tsay, 2005). The process of
understanding asset returns can be aided by the use of methods for analysis and prediction on
financial time series data. In this context, one can analyze aspects of the returns on individual
assets, as well as relationships between the returns of assets through various means.Furthermore,
one can ideally predict these returns accurately through time series prediction methods. 
FinPred offers functionality to help address these causes. Firstly, the package can be used
to perform data pre-processing by converting price data to return data, and by creating 
windowed data from a given time series. Moreover, the package contains functions to
visualize summary statistics for and correlations between given assets. Lastly, there are
functions to perform model selection for different time series prediction and machine learning methods given a time series, that find the hyperparameters yielding the lowest average prediction error over a rolling window. 

## Installation
You can install the development version of FinPred from [GitHub](https://github.com/jeroda7105/FinPred) with:

``` r
# install.packages("devtools")
devtools::install_github("jeroda7105/FinPred")

```
The package can then be imported with the command
``` {r}
library(FinPred)
```

## Using the Package
For this example, we will begin by importing real time series data for $SPY, 
an exchange traded fund (ETF) which attempts to track the S&P 500 Index, $GLD, 
an ETF which attempts to track the price of gold, and $TLT, which attempts to 
track the price of U.S. treasury bonds with 20 or more years until maturity. 
The data to be used are adjusted closing prices from yahoo finance, extracted using
the quantmod R package (Ryan & Ulrich, 2022). 

First, the data is imported as such:

``` {r}
# Getting daily data for an ETF which tracks the price of the SP500
spy_data = as.data.frame(quantmod::getSymbols('SPY', env = NULL))

# Getting daily data for an ETF which tracks the price of the gold
gld_data = as.data.frame(quantmod::getSymbols('GLD', env = NULL))

# Getting daily data for an ETF which tracks the price of the 20+ year US Treasury Bonds
tlt_data = as.data.frame(quantmod::getSymbols('TLT', env = NULL))

```

Then the adjusted closing prices are extracted for each series:
``` {r}
# Extract the adjusted closing prices for each asset
spy_adj_close = spy_data$SPY.Adjusted
gld_adj_close = gld_data$GLD.Adjusted
tlt_adj_close = tlt_data$TLT.Adjusted
```

Once we have each time series of prices, we can use the function prices_to_returns()
to convert them to series of returns in this way:

``` {r}
# Convert the prices to returns
spy_ret = prices_to_returns(spy_adj_close)
gld_ret = prices_to_returns(gld_adj_close)
tlt_ret = prices_to_returns(tlt_adj_close)
```


We can then combine these time series to create a dataframe containing them as columns, 
and then create a table of summary statistics using the function time_summary(). This
function gives the mean, standard deviation, skewness, and excess kurtosis for each 
given series in the dataframe. The skewness and kurtosis are calculated using the moments
R package (Komsta & Novomestky, 2022).

```{r}
# Create matrix woth the columns as time series
data = data.frame(spy_ret, gld_ret, tlt_ret)

# Creating table for dataframe with names
colnames(data) = c("SPY", "GLD", "TLT")

table = time_summary(data, has_names = TRUE)
table

```

Furthermore, using the R package igraph (Csardi & Nepusz, 2006), the function cor_graph() creates a weighted, undirected graph with
the vertices being the given assets and the edge weights being the correlations 
between their corresponding time series. For this example, it can be called as:

``` {r fig.width = 4, fig.height = 4}

# Create graph of correlations between the time series
cor_graph(data, has_names = TRUE)

```

For time series prediction, the ARMA model seen in Box et al., can be fit using the arima() function
within the stats R package (R Core Team, 2022). In this context, the number of autoregressive and moving average components, p and q, can be changed to improve the model fit. The function
arma_selection() can be used for these purposes. For example: 

``` {r}

# Standardizing the data
std_spy_ret = (spy_ret - rep(mean(spy_ret), length(spy_ret))) / sd(spy_ret)
std_gld_ret = (gld_ret - rep(mean(gld_ret), length(gld_ret))) / sd(gld_ret)
std_tlt_ret = (tlt_ret - rep(mean(tlt_ret), length(tlt_ret))) / sd(tlt_ret)

# Get training data from one of the time series
n = length(std_spy_ret)
train_idxs = floor(n*0.95)
std_spy_ret_train = std_spy_ret[1:train_idxs]

# Testing parameter tuning with ARMA on one of the series
p_vals = c(3:6)
q_vals = c(4:7)


arma_params = arma_selection(std_spy_ret_train, n_splits = 10, p_vals, q_vals)
arma_params

```

Supervised learning models require predictors and an output, so for univariate time
series, windowed data containing previous observations can be used as the predictors 
in these models. The function windowed_data() can be used to create these as such:

``` {r}

# Function to create windowed data

windowed_spy_ret = windowed_data(std_spy_ret_train, 5)
windowed_spy_ret[1:3, ]

```


One machine learning method that can be used for prediction is the Random Forest model
(Breiman, 2001). The function rf_selection() can be used to tune hyperparameters 
for this model using the implementation from the randomForest R package (Liaw & Wiener, 2002).
An example of it's use on this data is:

``` {r}

n_trees = c(500, 750, 1000)
node_sizes = c(3, 5, 7)

rf_params = rf_selection(std_spy_ret_train, n_splits = 10, window_size = 10, n_trees = n_trees,
                         node_sizes = node_sizes)
rf_params

```

Similarly, Support Vector Machines, can be used for such a regression task (Cortes & Vapnik, 1995).  The function svr_selection() can be used to tune hyperparameters 
for this model using the svm() function from the e1071 R package (Meyer et al., 2022).
Below is how it can be used:


``` {r}

# Function to tune parameters for svr
gamma_vals = c(0.001, 0.01, 0.1)
C_vals = c(0.5, 1, 2)
epsilon_vals = c(0.05, 0.1, 0.2)

svr_params = svr_selection(std_spy_ret_train, n_splits = 10, window_size = 10, gamma_vals = gamma_vals,
                           C_vals = C_vals, epsilon_vals = epsilon_vals)

svr_params

```

Lastly, the XGBoost model can be used for prediction in the setting of supervised learning (Chen et al., 2016).  The function xgboost_selection() can be used to tune hyperparameters 
for this model using the xgboost() function from the xgboost R package (Chen et al., 2022).
An example of its use is:


``` {r}

eta_vals = c(0.75, 1, 1.1)
gamma_vals = c(1.0e-2, 0.1, 0.25)
max_depths = c(3, 4, 5)
lambda_vals = c(0.1, 0.25, 0.5)
nrounds = c(3, 4, 5)

xgb_params = xgboost_selection(std_spy_ret_train, nthread = 1, n_splits = 10, window_size = 10,
                               eta_vals = eta_vals, gamma_vals = gamma_vals,
                               max_depths = max_depths, lambda_vals = lambda_vals,
                               nrounds = nrounds)
xgb_params




```

The following code presents an example of using the previously obtained hyperparameters
for Support Vector Machines to fit a model and then asses the performance on future values:

``` {r}
# Create supervised data for svm
window_size = 10
X = windowed_data(std_spy_ret, window_size = window_size)

n = nrow(X)

# Account for the size of the window in the data
y = std_spy_ret[window_size + 1 : n]

train_idxs = floor(n*0.95)

# Split into train and test
X_train =  X[1:train_idxs, ]
X_test =  X[(train_idxs + 1):n, ]

y_train = y[1:train_idxs]
y_test = y[(train_idxs + 1):n]

# Fit a model with chosen parameters on data
svr_model = e1071::svm(X_train, y_train, gamma = svr_params$gamma,
                       C = svr_params$C, epsilon = svr_params$epsilon)

# Get predicted values
pred_vals = predict(svr_model, X_test)

# Calculate the error and add to this combination of parameters
error = sum((pred_vals - y_test)^2) / length(y_test)
error


# Overlay predictions
plot(y_test, type = "l")
lines(pred_vals, type = "l", col = "blue")

# Get proportion of correct directional movements predicted
sum(sign(y_test) == sign(pred_vals)) / length(y_test)

```

## References
Box, G. E. P., Jenkins, G. M., & Reinsel, G. C. (1994). Time Series Analysis: Forecasting and Control. Prentice Hall. 

Breiman, L. (2001). Random Forests. Machine Learning, 45(1), 5–32. https://doi.org/10.1023/a:1010933404324 

Chen, T., & Guestrin, C. (2016). XGBoost. Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. https://doi.org/10.1145/2939672.2939785 

Chen T, He T, Benesty M, Khotilovich V, Tang Y, Cho H, Chen K, Mitchell R, Cano I,
  Zhou T, Li M, Xie J, Lin M, Geng Y, Li Y, Yuan J (2022). _xgboost: Extreme
  Gradient Boosting_. R package version 1.6.0.1,
  <https://CRAN.R-project.org/package=xgboost>.

Cortes, C., & Vapnik, V. (1995). Support-Vector Networks. Machine Learning, 20(3), 273–297. https://doi.org/10.1007/bf00994018 

Csardi G, Nepusz T: The igraph software package for complex network research,
  InterJournal, Complex Systems 1695. 2006. https://igraph.org

Komsta L, Novomestky F (2022). _moments: Moments, Cumulants, Skewness, Kurtosis
  and Related Tests_. R package version 0.14.1,
  <https://CRAN.R-project.org/package=moments>.

Liaw A., Wiener  M. (2002). Classification and Regression by randomForest. R
  News 2(3), 18--22.

Meyer D, Dimitriadou E, Hornik K, Weingessel A, Leisch F (2022). _e1071: Misc
  Functions of the Department of Statistics, Probability Theory Group (Formerly:
  E1071), TU Wien_. R package version 1.7-11,
  <https://CRAN.R-project.org/package=e1071>.

R Core Team (2022). R: A language and environment for statistical computing. R
  Foundation for Statistical Computing, Vienna, Austria. URL
  https://www.R-project.org/.

Ryan JA, Ulrich JM (2022). _quantmod: Quantitative Financial Modelling Framework_.
  R package version 0.4.20, <https://CRAN.R-project.org/package=quantmod>.

Tsay, R. S. (2010). Analysis of Financial Time Series. John Wiley & Sons.


